# ğŸ“Œ Lista potencjalnych ulepszeÅ„ projektu AlphaChess

## ğŸ§  **Optymalizacja architektury sieci neuronowej**
- Zmiana reprezentacji danych wejÅ›ciowych (feature engineering), ktÃ³ra moÅ¼e zwiÄ™kszyÄ‡ efektywnoÅ›Ä‡ sieci nawet o 180 punktÃ³w Elo ([arxiv.org](https://arxiv.org/html/2304.14918v2)).
- ZwiÄ™kszenie liczby filtrÃ³w splotowych w policy head z 3 do 32 w celu przyspieszenia treningu ([scitepress.org](https://www.scitepress.org/PublishedPapers/2021/102459/102459.pdf)).
- Testowanie warstw Squeeze-and-Excitation w blokach rezydualnych, uwzglÄ™dniajÄ…c bilans miÄ™dzy wydajnoÅ›ciÄ… a kosztem ([arxiv.org](https://arxiv.org/pdf/2109.11602.pdf)).

### Optymalizacja algorytmu Monte Carlo Tree Search
- MoÅ¼liwe jest wykorzystanie Monte Carlo Graph Search (MCGS), ktÃ³ry poprzez wykorzystanie transpozycji pozycji zmniejsza zuÅ¼ycie pamiÄ™ci o 30â€“70% ([ml-research.github.io](https://ml-research.github.io/papers/czech2021icaps_mcgs.pdf)).
- AlternatywÄ… lub uzupeÅ‚nieniem UCT jest epsilon-greedy exploration, czyli losowe wybieranie ruchÃ³w z pewnym prawdopodobieÅ„stwem w celu unikniÄ™cia lokalnych minimÃ³w ([geeksforgeeks.org](https://www.geeksforgeeks.org/epsilon-greedy-algorithm-in-reinforcement-learning/)).
- Zastosowanie techniki â€Playout Capsâ€, polegajÄ…cej na redukcji liczby symulacji w mniej perspektywicznych ruchach, moÅ¼e przyspieszyÄ‡ trening o okoÅ‚o 27% bez duÅ¼ych strat jakoÅ›ciowych ([scitepress.org](https://www.scitepress.org/PublishedPapers/2021/102459/102459.pdf)).

### Usprawnienia procesu treningowego
- MoÅ¼liwe jest wykorzystanie podejÅ›cia Path Consistency (PC), ktÃ³re przyspiesza konwergencjÄ™ modelu i osiÄ…ga lepsze rezultaty z mniejszÄ… liczbÄ… gier treningowych ([proceedings.mlr.press](https://proceedings.mlr.press/v162/zhao22h/zhao22h.pdf)).
- Warto rozwaÅ¼yÄ‡ uÅ¼ycie Q-values generowanych w MCTS jako dodatkowego celu treningowego zamiast jedynie koÅ„cowego wyniku gry, co moÅ¼e zapewniÄ‡ bardziej stabilne uczenie ([reddit.com](https://www.reddit.com/r/MachineLearning/comments/8ubkrl/d_improvement_to_the_alphazero_value_target/)).
- Trening populacyjny (Population-Based Training, PBT) pozwala na dynamicznÄ… optymalizacjÄ™ hiperparametrÃ³w poprzez rÃ³wnolegÅ‚e trenowanie wielu modeli i ich adaptacjÄ™ w trakcie uczenia ([arxiv.org](https://arxiv.org/abs/2003.06212)).

### Optymalizacja zarzÄ…dzania danymi
- RozwaÅ¼enie augmentacji danych treningowych z uÅ¼yciem symetrii szachownicy, co zwiÄ™ksza efektywnoÅ›Ä‡ treningu bez generowania nowych partii ([scitepress.org](https://www.scitepress.org/PublishedPapers/2021/102459/102459.pdf)).
- MoÅ¼na rÃ³wnieÅ¼ zastosowaÄ‡ priorytetyzacjÄ™ danych, skupiajÄ…c trening na trudnych lub nowych pozycjach.
- Optymalizacja procesu Å‚adowania danych (asynchroniczne wczytywanie, prefetching, cacheâ€™owanie danych) moÅ¼e zwiÄ™kszyÄ‡ wykorzystanie GPU ([aaai.org](https://ojs.aaai.org/index.php/AAAI/article/view/5454/5310)).

### Poprawa efektywnoÅ›ci gier koÅ„cowych
- MoÅ¼liwe jest stworzenie specjalnej reprezentacji cech gier koÅ„cowych (np. aktywnoÅ›Ä‡ krÃ³la, odlegÅ‚oÅ›ci miÄ™dzy pionami i krÃ³lami), co poprawia dokÅ‚adnoÅ›Ä‡ oceny tych pozycji ([arxiv.org](https://arxiv.org/html/2304.14918v2)).
- Implementacja prostego solvera pozycji koÅ„cowych umoÅ¼liwia dokÅ‚adne rozegranie elementarnych gier koÅ„cowych takich jak matowanie krÃ³lem i hetmanem przeciwko krÃ³lowi ([ml-research.github.io](https://ml-research.github.io/papers/czech2021icaps_mcgs.pdf)).
- Integracja tabel gier koÅ„cowych (np. Syzygy Tablebases) zapewnia perfekcyjnÄ… grÄ™ dla pozycji z ograniczonÄ… liczbÄ… figur ([arxiv.org](https://arxiv.org/pdf/2109.11602.pdf)).
- Dostosowanie funkcji wartoÅ›ci tak, aby uwzglÄ™dniaÅ‚a osobno prawdopodobieÅ„stwo remisu, umoÅ¼liwiajÄ…c bardziej precyzyjnÄ… ocenÄ™ gier koÅ„cowych ([scitepress.org](https://www.scitepress.org/PublishedPapers/2021/102459/102459.pdf)).

### Optymalizacje wdroÅ¼eniowe
- Profilowanie wydajnoÅ›ci modelu przy uÅ¼yciu narzÄ™dzi takich jak cProfile czy tensorboard profiler pomoÅ¼e w identyfikacji wÄ…skich gardeÅ‚ ([TensorFlow profiler](https://www.tensorflow.org/guide/profiler)).
- RozwaÅ¼enie technik kwantyzacji lub pruning do przyspieszenia inferencji bez znaczÄ…cej utraty jakoÅ›ci.
- Stopniowa integracja i regularne testy poszczegÃ³lnych ulepszeÅ„, by uniknÄ…Ä‡ konfliktÃ³w miÄ™dzy rÃ³Å¼nymi optymalizacjami.

### Integracja z serwisem Lichess
- MoÅ¼liwa jest integracja bota AlphaChess z serwisem Lichess przy uÅ¼yciu [API Lichess botÃ³w](https://github.com/lichess-bot-devs/lichess-bot).
- Analiza rozegranych partii na Lichess moÅ¼e sÅ‚uÅ¼yÄ‡ do zbierania wartoÅ›ciowych danych treningowych.
- DziÄ™ki integracji moÅ¼liwe bÄ™dzie prowadzenie automatycznych benchmarkÃ³w siÅ‚y bota w rozgrywkach online na Lichess.